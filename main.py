import json

@st.cache_data
def load_admit_profiles():
    with open("config/admit_profiles.json", "r", encoding="utf-8") as f:
        return json.load(f)

admit_profiles = load_admit_profiles()

import streamlit as st
import pdfplumber
from openai import OpenAI

from utils import parse_student_record, extract_books, generate_pdf, admin_zip_download
from analysis import run_gpt_analysis, summarize_book

st.set_page_config(page_title="AI ìƒê¸°ë¶€ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])


# -------------------------
# ë¡œê·¸ì¸
# -------------------------
if "user" not in st.session_state:
    st.session_state.user = None

if st.session_state.user is None:
    st.title("AI ê¸°ë°˜ ìƒê¸°ë¶€ ë¶„ì„ ì‹œìŠ¤í…œ")

    name = st.text_input("ì´ë¦„")
    school = st.text_input("í•™êµëª…")
    year = st.number_input("ì§€ì› í•™ë…„ë„", value=2025, step=1)

    if st.button("ë¡œê·¸ì¸"):
        st.session_state.user = {
            "name": name,
            "school": school,
            "year": year,
        }
    st.stop()

st.sidebar.success(f"{st.session_state.user['name']}ë‹˜ ë¡œê·¸ì¸ë¨")


# -------------------------
# ê´€ë¦¬ì í˜ì´ì§€
# -------------------------
st.sidebar.subheader("ê´€ë¦¬ì")
if st.sidebar.checkbox("ê´€ë¦¬ì í˜ì´ì§€ ì—´ê¸°"):
    st.title("ê´€ë¦¬ì í˜ì´ì§€")

    if st.button("ì „ì²´ ZIP ë‹¤ìš´ë¡œë“œ"):
        zip_path = admin_zip_download()
        with open(zip_path, "rb") as z:
            st.download_button("ZIP ë‹¤ìš´ë¡œë“œ", z, file_name="all_reports.zip")

    st.stop()


# -------------------------
# ìƒê¸°ë¶€ ì—…ë¡œë“œ
# -------------------------
st.header("1. ìƒí™œê¸°ë¡ë¶€ ì—…ë¡œë“œ")
uploaded_pdf = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_pdf:
    with pdfplumber.open(uploaded_pdf) as pdf:
        text = ""
        for page in pdf.pages:
            text += page.extract_text() + "\n"

    st.session_state.raw = text
    st.success("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")


# -------------------------
# ë¶„ì„ ì¡°ê±´ ì…ë ¥
# -------------------------
st.header("2. í¬ë§ ëŒ€í•™Â·í•™ê³¼ ì…ë ¥")

target_univ = st.text_input("í¬ë§ ëŒ€í•™")
target_major = st.text_input("í¬ë§ í•™ê³¼")
target_values = st.text_area("ëŒ€í•™ ì¸ì¬ìƒ ë˜ëŠ” ì „í˜• í‰ê°€ ìš”ì†Œ")


if st.button("ë¶„ì„ ì‹œì‘"):
    with st.spinner("AI ë¶„ì„ ì¤‘..."):

        sections = parse_student_record(st.session_state.raw)
        books = extract_books(st.session_state.raw)

        # GPT ì¢…í•© ë¶„ì„
        gpt_result = run_gpt_analysis(
            client=client,
            sections=sections,
            target_univ=target_univ,
            target_major=target_major,
            target_values=target_values
        )

        # ë…ì„œ ë¶„ì„ ìˆ˜í–‰
        book_results = []
        for b in books:
            summary = summarize_book(client, b)
            book_results.append({"title": b["title"], "author": b["author"], "summary": summary})

        st.session_state.analysis = gpt_result
        st.session_state.books = book_results



# -------------------------
# ë¶„ì„ ê²°ê³¼ ì¶œë ¥
# -------------------------
if "analysis" in st.session_state:
    st.header("3. ë¶„ì„ ê²°ê³¼")

    st.subheader("ì¢…í•© ë¶„ì„ ê²°ê³¼")
    st.write(st.session_state.analysis)

    st.subheader("ğŸ“š ë…ì„œí™œë™ ë¶„ì„")

    for b in st.session_state.books:
        with st.container():
            st.markdown(f"### **{b['title']} â€” {b['author']}**")
            st.markdown("---")
            st.write("\n".join(b["summary"]["summary_text"]))
            st.write("**ì „ê³µ ì—°ê³„:**")
            st.write("\n".join(b["summary"]["major_links"]))
            st.write("**í”„ë¡œì íŠ¸ ì œì•ˆ:**")
            st.write("\n".join(b["summary"]["projects"]))
            st.markdown("---")


    st.subheader("ğŸ§  ë§ˆì¸ë“œë§µ ì‹œê°í™”")
    display_mindmap(st.session_state.analysis["mindmap"])
   
    # PDF ì €ì¥
    if st.button("PDF ì €ì¥"):
        pdf_bytes = generate_pdf(
            st.session_state.user,
            st.session_state.analysis,
            st.session_state.books
        )
        st.download_button("PDF ë‹¤ìš´ë¡œë“œ", pdf_bytes, file_name="analysis.pdf")
from pyvis.network import Network
import json
import streamlit.components.v1 as components


def display_mindmap(mindmap_json):
    """
    GPTê°€ ìƒì„±í•œ ë§ˆì¸ë“œë§µ JSONì„ pyvis ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ë¡œ ë Œë”ë§
    """

    # JSON ë¬¸ìì—´ì„ dictë¡œ ë³€í™˜
    data = json.loads(mindmap_json)

    net = Network(height="600px", width="100%", bgcolor="#FFFFFF", font_color="black")

    net.add_node("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", shape="ellipse", color="#FFB347")

    # 1ì°¨ ë…¸ë“œ: summary, strengths, weaknesses, activities
    net.add_node("ìš”ì•½", color="#77DD77")
    net.add_edge("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", "ìš”ì•½")

    net.add_node("ê°•ì ", color="#AEC6CF")
    net.add_edge("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", "ê°•ì ")

    net.add_node("ì•½ì ", color="#FF6961")
    net.add_edge("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", "ì•½ì ")

    net.add_node("í™œë™", color="#FDFD96")
    net.add_edge("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", "í™œë™")

    # summary
    net.add_node(data["summary"], shape="box")
    net.add_edge("ìš”ì•½", data["summary"])

    # strengths
    for s in data["strengths"]:
        net.add_node(s, color="#ADD8E6")
        net.add_edge("ê°•ì ", s)

    # weaknesses
    for w in data["weaknesses"]:
        net.add_node(w, color="#FFB6B6")
        net.add_edge("ì•½ì ", w)

    # activities
    for key, items in data["activities"].items():
        net.add_node(key, color="#FFF380")
        net.add_edge("í™œë™", key)

        for item in items:
            net.add_node(item, shape="box")
            net.add_edge(key, item)

    # HTML ìƒì„±
    net.set_options('''
        var options = {
          "edges": {"smooth": false},
          "physics": {"enabled": true}
        }
    ''')

    html = net.generate_html("mindmap.html")
def calculate_pattern_match(student_text, university, major):
    profile = admit_profiles.get(university, {}).get(major, {})
    if not profile:
        return None

    def score_keywords(keywords):
        score = 0
        for kw in keywords:
            if kw in student_text:
                score += 1
        return score / max(len(keywords), 1)

    result = {
        "í•µì‹¬ì—­ëŸ‰ ì ìˆ˜": score_keywords(profile.get("í•µì‹¬ì—­ëŸ‰", [])),
        "ì„¸íŠ¹ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("ì„¸íŠ¹íŒ¨í„´", [])),
        "íƒêµ¬ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("íƒêµ¬Â·í”„ë¡œì íŠ¸ íŒ¨í„´", [])),
        "ë…ì„œ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("ë…ì„œ íŒ¨í„´", [])),
        "ë¹„êµê³¼ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("ë¹„êµê³¼ íŒ¨í„´", [])),
    }

    # ì´ì  (ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥)
    result["ì´í•© ì ìˆ˜"] = (
        result["í•µì‹¬ì—­ëŸ‰ ì ìˆ˜"] * 0.30 +
        result["ì„¸íŠ¹ íŒ¨í„´ ì ìˆ˜"] * 0.30 +
        result["íƒêµ¬ íŒ¨í„´ ì ìˆ˜"] * 0.20 +
        result["ë…ì„œ íŒ¨í„´ ì ìˆ˜"] * 0.10 +
        result["ë¹„êµê³¼ íŒ¨í„´ ì ìˆ˜"] * 0.10
    )

    return result

    # Streamlitì— í‘œì‹œ
    components.html(html, height=650, scrolling=True)
