import streamlit as st
import pdfplumber
from openai import OpenAI
import json
from pyvis.network import Network
import streamlit.components.v1 as components

from utils import parse_student_record, extract_books, generate_pdf, admin_zip_download
from analysis import run_gpt_analysis, summarize_book


# -------------------------
# Streamlit ì„¤ì •
# -------------------------
st.set_page_config(page_title="AI ìƒê¸°ë¶€ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])


# -------------------------
# admit_profiles.json ë¡œë“œ
# -------------------------
@st.cache_data
def load_admit_profiles():
    with open("config/admit_profiles.json", "r", encoding="utf-8") as f:
        return json.load(f)

admit_profiles = load_admit_profiles()


# -------------------------
# íŒ¨í„´ ë§¤ì¹­ í•¨ìˆ˜
# -------------------------
def calculate_pattern_match(student_text, university, major):
    profile = admit_profiles.get(university, {}).get(major, {})
    if not profile:
        return None

    def score_keywords(keywords):
        score = 0
        for kw in keywords:
            if kw in student_text:
                score += 1
        return score / max(len(keywords), 1)

    result = {
        "í•µì‹¬ì—­ëŸ‰ ì ìˆ˜": score_keywords(profile.get("í•µì‹¬ì—­ëŸ‰", [])),
        "ì„¸íŠ¹ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("ì„¸íŠ¹íŒ¨í„´", [])),
        "íƒêµ¬ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("íƒêµ¬Â·í”„ë¡œì íŠ¸ íŒ¨í„´", [])),
        "ë…ì„œ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("ë…ì„œ íŒ¨í„´", [])),
        "ë¹„êµê³¼ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("ë¹„êµê³¼ íŒ¨í„´", [])),
    }

    result["ì´í•© ì ìˆ˜"] = (
        result["í•µì‹¬ì—­ëŸ‰ ì ìˆ˜"] * 0.30 +
        result["ì„¸íŠ¹ íŒ¨í„´ ì ìˆ˜"] * 0.30 +
        result["íƒêµ¬ íŒ¨í„´ ì ìˆ˜"] * 0.20 +
        result["ë…ì„œ íŒ¨í„´ ì ìˆ˜"] * 0.10 +
        result["ë¹„êµê³¼ íŒ¨í„´ ì ìˆ˜"] * 0.10
    )

    return result


# -------------------------
# ë§ˆì¸ë“œë§µ ì‹œê°í™” í•¨ìˆ˜
# -------------------------
def display_mindmap(mindmap_json):
    data = json.loads(mindmap_json)

    net = Network(height="600px", width="100%", bgcolor="#FFFFFF", font_color="black")
    net.add_node("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", shape="ellipse", color="#FFB347")

    # 1ì°¨ ë…¸ë“œ
    net.add_node("ìš”ì•½", color="#77DD77")
    net.add_edge("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", "ìš”ì•½")

    net.add_node("ê°•ì ", color="#AEC6CF")
    net.add_edge("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", "ê°•ì ")

    net.add_node("ì•½ì ", color="#FF6961")
    net.add_edge("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", "ì•½ì ")

    net.add_node("í™œë™", color="#FDFD96")
    net.add_edge("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", "í™œë™")

    # summary
    net.add_node(data["summary"], shape="box")
    net.add_edge("ìš”ì•½", data["summary"])

    # strengths
    for s in data["strengths"]:
        net.add_node(s, color="#ADD8E6")
        net.add_edge("ê°•ì ", s)

    # weaknesses
    for w in data["weaknesses"]:
        net.add_node(w, color="#FFB6B6")
        net.add_edge("ì•½ì ", w)

    # activities
    for key, items in data["activities"].items():
        net.add_node(key, color="#FFF380")
        net.add_edge("í™œë™", key)
        for item in items:
            net.add_node(item, shape="box")
            net.add_edge(key, item)

    html = net.generate_html("mindmap.html")
    return html


# -------------------------
# ë¡œê·¸ì¸
# -------------------------
if "user" not in st.session_state:
    st.session_state.user = None

if st.session_state.user is None:
    st.title("AI ê¸°ë°˜ ìƒê¸°ë¶€ ë¶„ì„ ì‹œìŠ¤í…œ")

    name = st.text_input("ì´ë¦„")
    school = st.text_input("í•™êµëª…")
    year = st.number_input("ì§€ì› í•™ë…„ë„", value=2025, step=1)

    if st.button("ë¡œê·¸ì¸"):
        st.session_state.user = {"name": name, "school": school, "year": year}
    st.stop()

st.sidebar.success(f"{st.session_state.user['name']}ë‹˜ ë¡œê·¸ì¸ë¨")


# -------------------------
# ê´€ë¦¬ì í˜ì´ì§€
# -------------------------
st.sidebar.subheader("ê´€ë¦¬ì")
if st.sidebar.checkbox("ê´€ë¦¬ì í˜ì´ì§€ ì—´ê¸°"):
    st.title("ê´€ë¦¬ì í˜ì´ì§€")

    if st.button("ì „ì²´ ZIP ë‹¤ìš´ë¡œë“œ"):
        zip_path = admin_zip_download()
        with open(zip_path, "rb") as z:
            st.download_button("ZIP ë‹¤ìš´ë¡œë“œ", z, file_name="all_reports.zip")

    st.stop()


# -------------------------
# 1. ìƒê¸°ë¶€ ì—…ë¡œë“œ
# -------------------------
st.header("1. ìƒí™œê¸°ë¡ë¶€ ì—…ë¡œë“œ")
uploaded_pdf = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_pdf:
    with pdfplumber.open(uploaded_pdf) as pdf:
        text = ""
        for page in pdf.pages:
            extracted = page.extract_text()
            if extracted:
                text += extracted + "\n"

    st.session_state.raw = text
    st.success("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")


# -------------------------
# 2. ë¶„ì„ ì¡°ê±´ ì…ë ¥
# -------------------------
st.header("2. í¬ë§ ëŒ€í•™Â·í•™ê³¼ ì…ë ¥")

target_univ = st.text_input("í¬ë§ ëŒ€í•™")
target_major = st.text_input("í¬ë§ í•™ê³¼")
target_values = st.text_area("ëŒ€í•™ ì¸ì¬ìƒ ë˜ëŠ” ì „í˜• í‰ê°€ ìš”ì†Œ")


# -------------------------
# 3. ë¶„ì„ ì‹œì‘
# -------------------------
if st.button("ë¶„ì„ ì‹œì‘"):

    # íŒ¨í„´ ë§¤ì¹­ ê³„ì‚°
    pattern_result = calculate_pattern_match(
        st.session_state.raw,
        target_univ,
        target_major
    )
    st.session_state["pattern_result"] = pattern_result

    with st.spinner("AI ë¶„ì„ ì¤‘..."):

        # ìƒê¸°ë¶€ ì„¹ì…˜ ìë™ ë¶„ë¦¬
        sections = parse_student_record(st.session_state.raw)

        # ë…ì„œëª©ë¡ ì¶”ì¶œ
        books = extract_books(st.session_state.raw)

        # GPT ì¢…í•© ë¶„ì„
        gpt_result = run_gpt_analysis(
            client=client,
            sections=sections,
            target_univ=target_univ,
            target_major=target_major,
            target_values=target_values
        )

        # ë…ì„œ ë¶„ì„
        book_results = []
        for b in books:
            summary = summarize_book(client, b)
            book_results.append({
                "title": b["title"],
                "author": b["author"],
                "summary": summary
            })

        st.session_state.analysis = gpt_result
        st.session_state.books = book_results


# -------------------------
# 4. ë¶„ì„ ê²°ê³¼ ì¶œë ¥
# -------------------------
if "analysis" in st.session_state:
    st.header("3. ë¶„ì„ ê²°ê³¼")

    # íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼
    st.subheader("ğŸ¯ ëŒ€í•™Â·ì „ê³µ íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼")
    st.write(st.session_state["pattern_result"])

    # GPT ì¢…í•© ë¶„ì„
    st.subheader("ì¢…í•© ë¶„ì„ ê²°ê³¼")
    st.write(st.session_state.analysis)

    # ë…ì„œ ë¶„ì„ ì¶œë ¥
    st.subheader("ğŸ“š ë…ì„œí™œë™ ë¶„ì„")
    for b in st.session_state.books:
        st.markdown(f"### **{b['title']} â€” {b['author']}**")
        st.markdown("---")
        st.write("\n".join(b["summary"]["summary_text"]))
        st.write("**ì „ê³µ ì—°ê³„:**")
        st.write("\n".join(b["summary"]["major_links"]))
        st.write("**í”„ë¡œì íŠ¸ ì œì•ˆ:**")
        st.write("\n".join(b["summary"]["projects"]))
        st.markdown("---")

    # ë§ˆì¸ë“œë§µ ì‹œê°í™”
    st.subheader("ğŸ§  ë§ˆì¸ë“œë§µ ì‹œê°í™”")
    html = display_mindmap(st.session_state.analysis["mindmap"])
    components.html(html, height=650, scrolling=True)

    # PDF ì €ì¥
    if st.button("PDF ì €ì¥"):
        pdf_bytes = generate_pdf(
            st.session_state.user,
            st.session_state.analysis,
            st.session_state.books
        )
        st.download_button("PDF ë‹¤ìš´ë¡œë“œ", pdf_bytes, file_name="analysis.pdf")
