import streamlit as st
import pdfplumber
from openai import OpenAI
import json
from pyvis.network import Network
import streamlit.components.v1 as components

from utils import (
    parse_student_record,
    extract_books,
    generate_html_report,
    admin_zip_download
)

from analysis import run_gpt_analysis, summarize_book


# -------------------------------------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# -------------------------------------------------------
st.set_page_config(page_title="AI ìƒê¸°ë¶€ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")


# -------------------------------------------------------
# ì•”í˜¸ ì…ë ¥ (ì„ ìƒë‹˜ ì „ìš© ë³´ì•ˆ)
# -------------------------------------------------------
st.sidebar.header("ì ‘ì† ì¸ì¦")
password = st.sidebar.text_input("ì ‘ì† ì•”í˜¸ ì…ë ¥", type="password")

if password != st.secrets["ADMIN_PASSWORD"]:
    st.sidebar.warning("ì˜¬ë°”ë¥¸ ì•”í˜¸ë¥¼ ì…ë ¥í•´ì•¼ ì‹œìŠ¤í…œì´ í™œì„±í™”ë©ë‹ˆë‹¤.")
    st.stop()

# ì•”í˜¸ê°€ ë§ìœ¼ë©´ OpenAI í´ë¼ì´ì–¸íŠ¸ í™œì„±í™”
client = OpenAI(api_key=st.secrets["OPENAI_KEY"])


# -------------------------------------------------------
# í•©ê²© íŒ¨í„´ DB ë¡œë“œ
# -------------------------------------------------------
@st.cache_data
def load_admit_profiles():
    with open("config/admit_profiles.json", "r", encoding="utf-8") as f:
        return json.load(f)

admit_profiles = load_admit_profiles()


# -------------------------------------------------------
# íŒ¨í„´ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
# -------------------------------------------------------
def calculate_pattern_match(student_text, university, major):
    profile = admit_profiles.get(university, {}).get(major, {})
    if not profile:
        return None

    def score_keywords(keywords):
        return sum(kw in student_text for kw in keywords) / max(len(keywords), 1)

    result = {
        "í•µì‹¬ì—­ëŸ‰ ì ìˆ˜": score_keywords(profile.get("í•µì‹¬ì—­ëŸ‰", [])),
        "ì„¸íŠ¹ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("ì„¸íŠ¹íŒ¨í„´", [])),
        "íƒêµ¬ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("íƒêµ¬Â·í”„ë¡œì íŠ¸ íŒ¨í„´", [])),
        "ë…ì„œ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("ë…ì„œ íŒ¨í„´", [])),
        "ë¹„êµê³¼ íŒ¨í„´ ì ìˆ˜": score_keywords(profile.get("ë¹„êµê³¼ íŒ¨í„´", [])),
    }

    result["ì´í•© ì ìˆ˜"] = (
        result["í•µì‹¬ì—­ëŸ‰ ì ìˆ˜"] * 0.30 +
        result["ì„¸íŠ¹ íŒ¨í„´ ì ìˆ˜"] * 0.30 +
        result["íƒêµ¬ íŒ¨í„´ ì ìˆ˜"] * 0.20 +
        result["ë…ì„œ íŒ¨í„´ ì ìˆ˜"] * 0.10 +
        result["ë¹„êµê³¼ íŒ¨í„´ ì ìˆ˜"] * 0.10
    )

    return result


# -------------------------------------------------------
# ë§ˆì¸ë“œë§µ ì‹œê°í™” í•¨ìˆ˜
# -------------------------------------------------------
def display_mindmap(mindmap_json):
    data = json.loads(mindmap_json)

    net = Network(height="600px", width="100%", bgcolor="#FFFFFF", font_color="black")
    net.add_node("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", shape="ellipse", color="#FFB347")

    keys = ["summary", "strengths", "weaknesses", "activities"]
    colors = ["#77DD77", "#AEC6CF", "#FF6961", "#FDFD96"]
    labels = ["ìš”ì•½", "ê°•ì ", "ì•½ì ", "í™œë™"]

    for label, key, color in zip(labels, keys, colors):
        net.add_node(label, color=color)
        net.add_edge("í•™ìƒë¶€ í•µì‹¬êµ¬ì¡°", label)

    # summary
    net.add_node(data["summary"], shape="box")
    net.add_edge("ìš”ì•½", data["summary"])

    # strengths
    for s in data["strengths"]:
        net.add_node(s, color="#ADD8E6")
        net.add_edge("ê°•ì ", s)

    # weaknesses
    for w in data["weaknesses"]:
        net.add_node(w, color="#FFB6B6")
        net.add_edge("ì•½ì ", w)

    # activities
    for key, items in data["activities"].items():
        net.add_node(key, color="#FFF380")
        net.add_edge("í™œë™", key)
        for item in items:
            net.add_node(item, shape="box")
            net.add_edge(key, item)

    return net.generate_html("mindmap.html")


# -------------------------------------------------------
# ë¡œê·¸ì¸ ì²˜ë¦¬
# -------------------------------------------------------
if "user" not in st.session_state:
    st.session_state.user = None

if st.session_state.user is None:
    st.title("AI ê¸°ë°˜ ìƒê¸°ë¶€ ë¶„ì„ ì‹œìŠ¤í…œ")

    name = st.text_input("ì´ë¦„")
    school = st.text_input("í•™êµëª…")
    year = st.number_input("ì§€ì› í•™ë…„ë„", value=2025)

    if st.button("ë¡œê·¸ì¸"):
        st.session_state.user = {"name": name, "school": school, "year": year}

    st.stop()

st.sidebar.success(f"{st.session_state.user['name']}ë‹˜ ë¡œê·¸ì¸ë¨")


# -------------------------------------------------------
# ê´€ë¦¬ì í˜ì´ì§€
# -------------------------------------------------------
st.sidebar.subheader("ê´€ë¦¬ì ë„êµ¬")
if st.sidebar.checkbox("ê´€ë¦¬ì ZIP ë‹¤ìš´ë¡œë“œ"):
    st.title("ê´€ë¦¬ì í˜ì´ì§€")

    if st.button("ì „ì²´ ZIP ë‹¤ìš´ë¡œë“œ"):
        zip_path = admin_zip_download()
        with open(zip_path, "rb") as z:
            st.download_button("ZIP ë‹¤ìš´ë¡œë“œ", z, file_name="all_reports.zip")

    st.stop()


# -------------------------------------------------------
# PDF ì—…ë¡œë“œ
# -------------------------------------------------------
st.header("1. ìƒí™œê¸°ë¡ë¶€ ì—…ë¡œë“œ")
uploaded_pdf = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

if uploaded_pdf:
    with pdfplumber.open(uploaded_pdf) as pdf:
        text = "\n".join(page.extract_text() or "" for page in pdf.pages)

    st.session_state.raw = text
    st.success("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")


# -------------------------------------------------------
# í¬ë§ ëŒ€í•™/í•™ê³¼ ì…ë ¥
# -------------------------------------------------------
st.header("2. í¬ë§ ëŒ€í•™Â·í•™ê³¼ ì…ë ¥")

target_univ = st.text_input("í¬ë§ ëŒ€í•™")
target_major = st.text_input("í¬ë§ í•™ê³¼")
target_values = st.text_area("ëŒ€í•™ ì¸ì¬ìƒ ë˜ëŠ” ì „í˜• ìš”ì†Œ")


# -------------------------------------------------------
# ë¶„ì„ ì‹¤í–‰
# -------------------------------------------------------
if st.button("ë¶„ì„ ì‹œì‘"):

    st.session_state["pattern_result"] = calculate_pattern_match(
        st.session_state.raw, target_univ, target_major
    )

    with st.spinner("AI ë¶„ì„ ì¤‘..."):

        sections = parse_student_record(st.session_state.raw)
        books = extract_books(st.session_state.raw)

        gpt_result = run_gpt_analysis(
            client=client,
            sections=sections,
            target_univ=target_univ,
            target_major=target_major,
            target_values=target_values
        )

        book_results = []
        for b in books:
            summary = summarize_book(client, b)
            book_results.append({
                "title": b["title"],
                "author": b["author"],
                "summary": summary
            })

        st.session_state.analysis = gpt_result
        st.session_state.books = book_results


# -------------------------------------------------------
# ë¶„ì„ ê²°ê³¼ ì¶œë ¥
# -------------------------------------------------------
if "analysis" in st.session_state:
    st.header("3. ë¶„ì„ ê²°ê³¼")

    st.subheader("ğŸ¯ íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼")
    st.write(st.session_state["pattern_result"])

    st.subheader("ì¢…í•© ë¶„ì„ ê²°ê³¼")
    st.write(st.session_state.analysis)

    st.subheader("ğŸ“š ë…ì„œí™œë™ ë¶„ì„")
    for b in st.session_state.books:
        st.markdown(f"### **{b['title']} â€” {b['author']}**")
        st.markdown("---")
        st.write("\n".join(b["summary"]["summary_text"]))
        st.write("**ì „ê³µ ì—°ê³„:**")
        st.write("\n".join(b["summary"]["major_links"]))
        st.write("**í”„ë¡œì íŠ¸ ì œì•ˆ:**")
        st.write("\n".join(b["summary"]["projects"]))
        st.markdown("---")

    st.subheader("ğŸ§  ë§ˆì¸ë“œë§µ ì‹œê°í™”")
    html = display_mindmap(st.session_state.analysis["mindmap"])
    components.html(html, height=650, scrolling=True)

    # HTML ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ
    if st.button("ë¦¬í¬íŠ¸ ì €ì¥ (HTML)"):
        html_bytes = generate_html_report(
            st.session_state.user,
            st.session_state.analysis,
            st.session_state.books
        )

        st.download_button(
            "ğŸ“¥ HTML ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
            html_bytes,
            file_name="analysis_report.html",
            mime="text/html"
        )
