import streamlit as st
import pdfplumber
import json
from openai import OpenAI
import streamlit.components.v1 as components

from utils import (
    parse_student_record,
    extract_books,
    generate_html_report,
    admin_zip_download
)
from analysis import run_gpt_analysis, summarize_book


# ==============================
# ê¸°ë³¸ ì„¤ì •
# ==============================
st.set_page_config(page_title="AI ìƒê¸°ë¶€ ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")


# ==============================
# ê´€ë¦¬ì ì¸ì¦
# ==============================
st.sidebar.header("ì ‘ì† ì¸ì¦")

password = st.sidebar.text_input("ì ‘ì† ì•”í˜¸", type="password")

if password != st.secrets["ADMIN_PASSWORD"]:
    st.sidebar.warning("ì˜¬ë°”ë¥¸ ì•”í˜¸ë¥¼ ì…ë ¥í•´ì•¼ ì‹œìŠ¤í…œì´ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    st.stop()

client = OpenAI(api_key=st.secrets["OPENAI_KEY"])


# ==============================
# í•™ê³¼ íŒ¨í„´ DB ë¡œë“œ
# ==============================
@st.cache_data
def load_admit_profiles():
    with open("config/admit_profiles.json", "r", encoding="utf-8") as f:
        return json.load(f)

admit_profiles = load_admit_profiles()


# ==============================
# íŒ¨í„´ ì ìˆ˜ ê³„ì‚°
# ==============================
def calculate_pattern_match(student_text, major):

    profile = admit_profiles.get(major, None)
    if not profile:
        return None

    def score_keywords(keywords):
        return sum(kw in student_text for kw in keywords) / max(len(keywords), 1)

    result = {
        "í•µì‹¬ì—­ëŸ‰": score_keywords(profile.get("í•µì‹¬ì—­ëŸ‰", [])),
        "ì„¸íŠ¹ íŒ¨í„´": score_keywords(profile.get("ì„¸íŠ¹íŒ¨í„´", [])),
        "íƒêµ¬ íŒ¨í„´": score_keywords(profile.get("íƒêµ¬Â·í”„ë¡œì íŠ¸ íŒ¨í„´", [])),
        "ë…ì„œ íŒ¨í„´": score_keywords(profile.get("ë…ì„œ íŒ¨í„´", [])),
        "ë¹„êµê³¼ íŒ¨í„´": score_keywords(profile.get("ë¹„êµê³¼ íŒ¨í„´", [])),
    }

    result["ì´í•© ì ìˆ˜"] = (
        result["í•µì‹¬ì—­ëŸ‰"] * 0.30 +
        result["ì„¸íŠ¹ íŒ¨í„´"] * 0.30 +
        result["íƒêµ¬ íŒ¨í„´"] * 0.20 +
        result["ë…ì„œ íŒ¨í„´"] * 0.10 +
        result["ë¹„êµê³¼ íŒ¨í„´"] * 0.10
    )

    return result


# ==============================
# ë¡œê·¸ì¸
# ==============================
if "user" not in st.session_state:
    st.session_state.user = None

if st.session_state.user is None:
    st.title("AI ê¸°ë°˜ ìƒê¸°ë¶€ ë¶„ì„ ì‹œìŠ¤í…œ")

    name = st.text_input("ì´ë¦„")
    school = st.text_input("í•™êµëª…")
    year = st.number_input("í•™ë…„ë„", value=2025)

    if st.button("ë¡œê·¸ì¸"):
        st.session_state.user = {"name": name, "school": school, "year": year}

    st.stop()

st.sidebar.success(f"{st.session_state.user['name']}ë‹˜ ë¡œê·¸ì¸ë¨")


# ==============================
# ê´€ë¦¬ì ZIP
# ==============================
st.sidebar.subheader("ê´€ë¦¬ì ë©”ë‰´")
if st.sidebar.checkbox("ZIP ë‹¤ìš´ë¡œë“œ"):
    st.title("ê´€ë¦¬ì ë‹¤ìš´ë¡œë“œ")
    if st.button("ì „ì²´ ZIP ìƒì„±"):
        path = admin_zip_download()
        with open(path, "rb") as f:
            st.download_button("ZIP ë‹¤ìš´ë¡œë“œ", f, file_name="all_reports.zip")
    st.stop()


# ==============================
# PDF ì—…ë¡œë“œ
# ==============================
st.header("1. ìƒí™œê¸°ë¡ë¶€ PDF ì—…ë¡œë“œ")

uploaded_pdf = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_pdf:
    with pdfplumber.open(uploaded_pdf) as pdf:
        text = "\n".join(page.extract_text() or "" for page in pdf.pages)

    st.session_state.raw = text
    st.success("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")


# ==============================
# í•™ê³¼ ì„ íƒ
# ==============================
st.header("2. í¬ë§ í•™ê³¼ ì„ íƒ")

all_majors = list(admit_profiles.keys())
target_major = st.selectbox("í¬ë§ í•™ê³¼", all_majors)


# ==============================
# ë¶„ì„ ì‹¤í–‰
# ==============================
if st.button("ë¶„ì„ ì‹œì‘"):

    if "raw" not in st.session_state:
        st.error("PDFë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
        st.stop()

    st.session_state.pattern_result = calculate_pattern_match(
        st.session_state.raw,
        target_major
    )

    with st.spinner("AI ë¶„ì„ ì¤‘..."):

        sections = parse_student_record(st.session_state.raw)
        books = extract_books(st.session_state.raw)

        gpt_result = run_gpt_analysis(
            client=client,
            sections=sections,
            target_univ=None,
            target_major=target_major,
            target_values=None
        )

        book_results = []
        for b in books:
            summary = summarize_book(client, b)
            book_results.append({
                "title": b["title"],
                "author": b["author"],
                "summary": summary,
            })

        st.session_state.analysis = gpt_result
        st.session_state.books = book_results


# ==============================
# ë¶„ì„ ê²°ê³¼ ì¶œë ¥
# ==============================
if "analysis" in st.session_state:

    st.header("3. ë¶„ì„ ê²°ê³¼")

    st.subheader("ğŸ¯ í•™ê³¼ íŒ¨í„´ ë§¤ì¹­ ì ìˆ˜")
    st.write(st.session_state.pattern_result)

    st.subheader("ğŸ“ ì¢…í•© ë¶„ì„ ê²°ê³¼")
    st.write(st.session_state.analysis)

    st.subheader("ğŸ“š ë…ì„œí™œë™ ë¶„ì„")
    for b in st.session_state.books:
        st.markdown(f"### ğŸ“˜ {b['title']} â€” {b['author']}")
        st.write("\n".join(b["summary"].get("summary_text", [])))
        st.write("\n".join(b["summary"].get("major_links", [])))
        st.write("\n".join(b["summary"].get("projects", [])))
        st.markdown("---")

    html_bytes = generate_html_report(
        st.session_state.user,
        st.session_state.analysis,
        st.session_state.books
    )

    st.download_button(
        "ğŸ“¥ HTML ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
        html_bytes,
        file_name="analysis_report.html",
        mime="text/html"
    )
